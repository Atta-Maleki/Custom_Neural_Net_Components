{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMjOJqZJfcio99hRW4FgdwL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"sGIX1Ynnt_V0"},"outputs":[],"source":[" def compute_gradients(self, loss, var_list, tape=None):\n","        \"\"\"Compute gradients of loss on trainable variables.\n","        Args:\n","          loss: `Tensor` or callable. If a callable, `loss` should take no\n","            arguments and return the value to minimize.\n","          var_list: list or tuple of `Variable` objects to update to minimize\n","            `loss`, or a callable returning the list or tuple of `Variable`\n","            objects. Use callable when the variable list would otherwise be\n","            incomplete before `minimize` since the variables are created at the\n","            first time `loss` is called.\n","          tape: (Optional) `tf.GradientTape`. If `loss` is provided as a\n","            `Tensor`, the tape that computed the `loss` must be provided.\n","        Returns:\n","          A list of (gradient, variable) pairs. Variable is always present, but\n","          gradient can be `None`.\n","        \"\"\"\n","        if not callable(loss) and tape is None:\n","            raise ValueError(\n","                \"`tape` is required when a `Tensor` loss is passed. \"\n","                f\"Received: loss={loss}, tape={tape}.\"\n","            )\n","        if tape is None:\n","            tape = tf.GradientTape()\n","        if callable(loss):\n","            with tape:\n","                if not callable(var_list):\n","                    tape.watch(var_list)\n","                loss = loss()\n","                if callable(var_list):\n","                    var_list = var_list()\n","\n","        grads = tape.gradient(loss, var_list)\n","        return list(zip(grads, var_list))"]}]}